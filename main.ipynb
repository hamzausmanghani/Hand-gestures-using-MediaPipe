{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ccd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d653063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40862449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n"
     ]
    }
   ],
   "source": [
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2952744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "class HandDetector:\n",
    "    def __init__(self, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
    "        self.hands = mpHands.Hands(max_num_hands=max_num_hands, min_detection_confidence=min_detection_confidence,\n",
    "                                   min_tracking_confidence=min_tracking_confidence)\n",
    "\n",
    "\n",
    "    def findHandLandMarks(self, image, handNumber=0, draw=False):\n",
    "        originalImage = image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # mediapipe needs RGB\n",
    "        results = self.hands.process(image)\n",
    "        landMarkList = []\n",
    "\n",
    "        if results.multi_hand_landmarks:  # returns None if hand is not found\n",
    "            hand = results.multi_hand_landmarks[handNumber] #results.multi_hand_landmarks returns landMarks for all the hands\n",
    "\n",
    "            for id, landMark in enumerate(hand.landmark):\n",
    "                # landMark holds x,y,z ratios of single landmark\n",
    "                imgH, imgW, imgC = originalImage.shape  # height, width, channel for image\n",
    "                xPos, yPos = int(landMark.x * imgW), int(landMark.y * imgH)\n",
    "                landMarkList.append([id, xPos, yPos])\n",
    "\n",
    "            if draw:\n",
    "                mpDraw.draw_landmarks(originalImage, hand, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        return landMarkList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866371e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand detector instance\n",
    "handDetector = HandDetector(min_detection_confidence=0.7)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    x, y, c = frame.shape\n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    handLandmarks = handDetector.findHandLandMarks(image=frame, draw=True)\n",
    "    className = ''\n",
    "    if len(handLandmarks) != 0:\n",
    "        # removing hand id \n",
    "        handLandmarks = [h[1:] for h in handLandmarks]\n",
    "        # Predict gesture\n",
    "        prediction = model.predict([handLandmarks])\n",
    "        # print(prediction)\n",
    "        classID = np.argmax(prediction)\n",
    "        className = classNames[classID]\n",
    "\n",
    "    # show the prediction on the frame\n",
    "    cv2.putText(frame, className, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Gesture detection\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the webcam and destroy all active windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b027d229",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "# audio controlling utilities\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# hand detector instance\n",
    "handDetector = HandDetector(min_detection_confidence=0.7)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    x, y, c = frame.shape\n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    handLandmarks = handDetector.findHandLandMarks(image=frame, draw=True)\n",
    "    if len(handLandmarks) != 0:\n",
    "        # removing hand id \n",
    "        handLandmarks = [h[1:] for h in handLandmarks]\n",
    "        x1, y1 = handLandmarks[4] #  thumb\n",
    "        x2, y2 = handLandmarks[8] # index\n",
    "        length = math.hypot(x2-x1, y2-y1)\n",
    "\n",
    "        #Hand range(length): 50-250\n",
    "        #Volume Range: (-65.25, 0.0)\n",
    "\n",
    "        volumeValue = np.interp(length, [50, 250], [-65.25, 0.0]) #coverting length to proportionate to volume range\n",
    "        volume.SetMasterVolumeLevel(volumeValue, None)\n",
    "\n",
    "\n",
    "        cv2.circle(frame, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(frame, (x2, y2), 15, (255, 0, 255), cv2.FILLED)\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Volume\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the webcam and destroy all active windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21b4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "# audio controlling utilities\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# hand detector instance\n",
    "handDetector = HandDetector(min_detection_confidence=0.7)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "circle_radius = 25\n",
    "centroid = (110,210)\n",
    "circle_color = (0,255,0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    _, frame = cap.read()\n",
    "    # Flip the frame vertically\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # constant circle\n",
    "    cv2.circle(frame, centroid, circle_radius ,circle_color, cv2.FILLED)\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    handLandmarks = handDetector.findHandLandMarks(image=frame, draw=False)\n",
    "    if len(handLandmarks) != 0:\n",
    "        index_finger = handLandmarks[8][1], handLandmarks[8][2] #  index finger\n",
    "        cv2.circle(frame, index_finger, 5, (0, 0, 0), cv2.FILLED)\n",
    "        dist = math.dist(centroid, index_finger)\n",
    "#         print(dist)\n",
    "        print(index_finger, centroid, \"------\", dist)\n",
    "        if dist <= circle_radius:\n",
    "            circle_color = (0,0,255)\n",
    "            print(\"pressed\")\n",
    "        else:\n",
    "            circle_color = (0,255,0)\n",
    "    cv2.imshow(\"Change in color\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the webcam and destroy all active windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
